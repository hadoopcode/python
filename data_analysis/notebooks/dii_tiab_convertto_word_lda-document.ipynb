{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对文本预料进行处理，生成4个向量，其中需要将文本转化为词，在此基础上转化为主题模型，取出主题对应的词；文档对应的主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LUO F', 'DAN J']]\n",
      "[['BEIJING SENSETIME TECHNOLOGY DEV CO LTD (BEIJ-Non-standard)', 'UNIV FOSHAN (UYFS-C)']]\n",
      "[['G06T', 'H04N']]\n",
      "['2016']\n",
      "['Method for training convolutional neural network, involves adjusting network parameters of convolutional neural network according to first difference and second difference. The method involves detecting (S100) a raw sample image containing target object label information and a scrambled sample image corresponding to the original sample image based on a convolutional neural network to obtain the original image for the original image. A first prediction information of the target object in the sample image and second prediction information for the target object in the scrambled sample image. A first difference between the first prediction information and the annotation information, and a second difference between the first prediction information and the second prediction information are determined (S200). The network parameters of the convolutional neural network is adjusted (S300) according to the first difference and the second difference. Method for training convolutional neural network. The method effectively reduces the inter-frame jitter of the video frame images in the detection process. (1) a video processing method; (2) a convolution neural network training device; (3) a video processing device; and (4) an electronic device.']\n",
      "[['LUO F', 'DAN J'], ['WANG R', 'ZHANG X', 'HE M', 'WANG J', 'WU G', 'RONG H', 'XIONG Y']]\n",
      "[['BEIJING SENSETIME TECHNOLOGY DEV CO LTD (BEIJ-Non-standard)', 'UNIV FOSHAN (UYFS-C)'], ['UNIV FOSHAN (UYFS-C)', 'FOSHAN YOUYIJIA TECHNOLOGY CO LTD (FOSH-Non-standard)', 'UNIV FOSHAN (UYFS-C)', 'FOSHAN YOUYIJIA TECHNOLOGY CO LTD (FOSH-Non-standard)']]\n",
      "[['G06T', 'H04N'], ['G06Q', 'G06N']]\n",
      "['2016', '2018']\n",
      "['Method for training convolutional neural network, involves adjusting network parameters of convolutional neural network according to first difference and second difference. The method involves detecting (S100) a raw sample image containing target object label information and a scrambled sample image corresponding to the original sample image based on a convolutional neural network to obtain the original image for the original image. A first prediction information of the target object in the sample image and second prediction information for the target object in the scrambled sample image. A first difference between the first prediction information and the annotation information, and a second difference between the first prediction information and the second prediction information are determined (S200). The network parameters of the convolutional neural network is adjusted (S300) according to the first difference and the second difference. Method for training convolutional neural network. The method effectively reduces the inter-frame jitter of the video frame images in the detection process. (1) a video processing method; (2) a convolution neural network training device; (3) a video processing device; and (4) an electronic device.', 'Short-term power load prediction method of power system, involves predicting actual power consumption of measured power load and obtaining predicted power consumption of measured power load according to determined network prediction model. The method involves establishing a deep belief network prediction model of a four-layer network structure. The actual power consumption of the measured power load is combined to train the deep belief network prediction model using an unsupervised greedy algorithm. The parameter values of each layer of the deep belief network prediction model are obtained and the activation function of the deep belief network prediction model is set. The mapping relationship between the input and output of the deep belief network prediction model is obtained through training and learning. The actual power consumption of the measured power load is predicted and the predicted power consumption of the measured power load is obtained according to the determined depth belief network prediction model. Short-term power load prediction method of power system. The depth belief network prediction network is introduced into the power load power prediction, and the internal relationship between the input and the output is learned to realize a prediction of the load power consumption for the period of time through the deep structure of the network. The short-term power load prediction process largely predicts the accuracy and speed of prediction and is created to predict the short-term power load conditions.']\n",
      "[['LUO F', 'DAN J'], ['WANG R', 'ZHANG X', 'HE M', 'WANG J', 'WU G', 'RONG H', 'XIONG Y'], ['PAN Z', 'DU P', 'YOU X', 'LIU N']]\n",
      "[['BEIJING SENSETIME TECHNOLOGY DEV CO LTD (BEIJ-Non-standard)', 'UNIV FOSHAN (UYFS-C)'], ['UNIV FOSHAN (UYFS-C)', 'FOSHAN YOUYIJIA TECHNOLOGY CO LTD (FOSH-Non-standard)', 'UNIV FOSHAN (UYFS-C)', 'FOSHAN YOUYIJIA TECHNOLOGY CO LTD (FOSH-Non-standard)'], ['UNIV SOUTHEAST (UYSE-C)']]\n",
      "[['G06T', 'H04N'], ['G06Q', 'G06N'], ['H04W', 'G06N']]\n",
      "['2016', '2018', '2017']\n",
      "['Method for training convolutional neural network, involves adjusting network parameters of convolutional neural network according to first difference and second difference. The method involves detecting (S100) a raw sample image containing target object label information and a scrambled sample image corresponding to the original sample image based on a convolutional neural network to obtain the original image for the original image. A first prediction information of the target object in the sample image and second prediction information for the target object in the scrambled sample image. A first difference between the first prediction information and the annotation information, and a second difference between the first prediction information and the second prediction information are determined (S200). The network parameters of the convolutional neural network is adjusted (S300) according to the first difference and the second difference. Method for training convolutional neural network. The method effectively reduces the inter-frame jitter of the video frame images in the detection process. (1) a video processing method; (2) a convolution neural network training device; (3) a video processing device; and (4) an electronic device.', 'Short-term power load prediction method of power system, involves predicting actual power consumption of measured power load and obtaining predicted power consumption of measured power load according to determined network prediction model. The method involves establishing a deep belief network prediction model of a four-layer network structure. The actual power consumption of the measured power load is combined to train the deep belief network prediction model using an unsupervised greedy algorithm. The parameter values of each layer of the deep belief network prediction model are obtained and the activation function of the deep belief network prediction model is set. The mapping relationship between the input and output of the deep belief network prediction model is obtained through training and learning. The actual power consumption of the measured power load is predicted and the predicted power consumption of the measured power load is obtained according to the determined depth belief network prediction model. Short-term power load prediction method of power system. The depth belief network prediction network is introduced into the power load power prediction, and the internal relationship between the input and the output is learned to realize a prediction of the load power consumption for the period of time through the deep structure of the network. The short-term power load prediction process largely predicts the accuracy and speed of prediction and is created to predict the short-term power load conditions.', 'Small base station switch control method based on deep neural network, involves calculating real value of predicted coordinate in sample error by using actual coordinate and predicted coordinate. The method involves sampling user information collected in a base station. The user number, access time, and user location information of accessing the base station are recorded. The user data collected by the base station is collated and merged into path data that can be trained by the model, and data samples of all users are combined to obtain a sample set that is ultimately used for training. A neural network model is constructed to select a fully connected neural network as the training model. The average square error is used to calculate the training error. The commonly used forward propagation method is used to obtain a training result during training. The reverse propagation method is used to update the parameters in the neural network. The real value of the predicted coordinate in the sample error is calculated by using the actual coordinate and the predicted coordinate. The data to be predicted is collected and the position of the user is predicted at the next time. Small base station switch control method based on deep neural network. The accuracy of prediction and the practicality of system can be improved.']\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import linecache\n",
    "import pandas as pd\n",
    "import os\n",
    "from string import punctuation\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "with open('test_patent.txt', 'r') as f:\n",
    "    patent_content=[]\n",
    "    patent_author=[]\n",
    "    patent_year=[]\n",
    "    patent_institution=[]\n",
    "    patent_IPC=[]    \n",
    "    content_str=\"\"\n",
    "        \n",
    "    title_str=\"\"\n",
    "    abstract_str=\"\"\n",
    "    \n",
    "    line=f.readline()\n",
    "    \n",
    "    while not line.startswith('EF'):\n",
    "        \n",
    "        if line.startswith(\"TI \"):\n",
    "            title_str=line.replace(\"TI \",\"\").strip().strip('\\n')+\" \"\n",
    "            #print(title_str)\n",
    "            line=f.readline()\n",
    "            \n",
    "        elif line.startswith(\"AU \"):\n",
    "            #print line\n",
    "            author_list=[line.replace(\"AU \",\"\").strip().strip('\\n')]\n",
    "            line=f.readline()\n",
    "            while line.startswith(\"   \"):\n",
    "                author_list.append(line.strip().strip('\\n'))\n",
    "                line=f.readline()                \n",
    "            patent_author.append(author_list)\n",
    "            print(patent_author)\n",
    "        \n",
    "        elif line.startswith(\"AE \"):\n",
    "            #print line\n",
    "            institution_list=[line.replace(\"AE \",\"\").strip().strip('\\n')]\n",
    "            line=f.readline()\n",
    "            while line.startswith(\"   \"):\n",
    "                institution_list.append(line.strip().strip('\\n'))\n",
    "                line=f.readline()                \n",
    "            patent_institution.append(institution_list)\n",
    "            print(patent_institution)\n",
    "        \n",
    "        elif line.startswith(\"AB \"):\n",
    "            abstract_str=line.replace(\"AB    NOVELTY - \",\"\").strip().strip('\\n')+\" \"\n",
    "            line=f.readline()\n",
    "            while line.startswith(\"   \"):                \n",
    "                if line.startswith(\"   DETAILED DESCRIPTION - \"):\n",
    "                    line=f.readline()\n",
    "                abstract_str=abstract_str+line.strip().strip('\\n')+\" \"               \n",
    "                #print(abstract_str)\n",
    "                line=f.readline()\n",
    "            if \"DESCRIPTION OF DRAWING(S) - \" in abstract_str:\n",
    "                index=abstract_str.index(\"DESCRIPTION OF DRAWING(S) - \")\n",
    "                abstract_str=abstract_str[:index]                \n",
    "            abstract_str=abstract_str.replace(\"USE - \",\"\").replace(\"ADVANTAGE - \",\"\")\n",
    "            #print(abstract_str)\n",
    "        \n",
    "        elif line.startswith(\"IP \"):\n",
    "            #print line\n",
    "            patent_IPC_list=line.replace(\"IP \",\"\").split(';')\n",
    "            patent_IPC_short_list=(re.split(r'-', ipc.strip(), maxsplit=1)[0] for ipc in patent_IPC_list)\n",
    "            patent_IPC_short_list=list(set(patent_IPC_short_list))\n",
    "            patent_IPC.append(patent_IPC_short_list)\n",
    "            print(patent_IPC)\n",
    "            line=f.readline()\n",
    "            \n",
    "        elif line.startswith(\"AD \"):\n",
    "            #print line\n",
    "            year=line[-5:].strip('\\n')        \n",
    "            patent_year.append(year)\n",
    "            print(patent_year)\n",
    "            line=f.readline()\n",
    "            \n",
    "        elif line.startswith(\"ER\"):\n",
    "            content_str=(title_str+abstract_str).strip('\\n').strip()\n",
    "            patent_content.append(content_str)\n",
    "            print(patent_content)\n",
    "            title_str=\"\"\n",
    "            abstract_str=\"\"\n",
    "            line=f.readline()\n",
    "            \n",
    "        else:    \n",
    "            line=f.readline()\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessDwpiText(object):\n",
    "    @classmethod\n",
    "    def get_term(cls, sentence, grammar, pos):\n",
    "        toks = cls.sent_tokenize(sentence)\n",
    "        for tok in toks:\n",
    "            for leaf in cls.leaves(tok, grammar, pos):\n",
    "                term = [cls.normalise(w) for w, t in leaf if cls.acceptable_word(w)]\n",
    "                print(term)\n",
    "                yield term\n",
    "\n",
    "    @staticmethod\n",
    "    def leaves(toks, grammar, pos):\n",
    "        \"\"\"\n",
    "        :param toks: 分句后的列表\n",
    "        :param grammar:\n",
    "        :param pos: 词性\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        chunker = nltk.RegexpParser(grammar)\n",
    "        postoks = nltk.tag.pos_tag(toks)\n",
    "        tree = chunker.parse(postoks)\n",
    "        # tree.draw()\n",
    "        for subtree in tree.subtrees(lambda t: t.label() == pos):\n",
    "            yield subtree.leaves()\n",
    "\n",
    "    @staticmethod\n",
    "    def sent_tokenize(sentence):\n",
    "        # return:  [[单词，单词],[单词，单词],...] 每个字列表为句子\n",
    "        for sentence in nltk.sent_tokenize(sentence):\n",
    "            tokenize = nltk.word_tokenize(sentence)\n",
    "            yield tokenize\n",
    "\n",
    "    # 过滤单词对的规则\n",
    "    @staticmethod\n",
    "    def acceptable_word(word):\n",
    "        return bool(not re.match(r'[{}]'.format(punctuation), word) and not re.search(r'\\d',\n",
    "                                                                                      word) and word.lower() not in stopwords.words(\n",
    "            'english') and 2 <= len(word) <= 40)\n",
    "\n",
    "    # 提取词干\n",
    "    @staticmethod\n",
    "    def normalise(word):\n",
    "        lemmatizer = nltk.WordNetLemmatizer()\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['method']\n",
      "['convolutional', 'neural', 'network']\n",
      "['network', 'parameter']\n",
      "['convolutional', 'neural', 'network']\n",
      "['first', 'difference']\n",
      "['second', 'difference']\n",
      "['method']\n",
      "[]\n",
      "['raw', 'sample', 'image']\n",
      "['target', 'object', 'label', 'information']\n",
      "['scrambled', 'sample', 'image']\n",
      "['original', 'sample', 'image']\n",
      "['convolutional', 'neural', 'network']\n",
      "['original', 'image']\n",
      "['original', 'image']\n",
      "['first', 'prediction', 'information']\n",
      "['target', 'object']\n",
      "['sample', 'image']\n",
      "['second', 'prediction', 'information']\n",
      "['target', 'object']\n",
      "['scrambled', 'sample', 'image']\n",
      "['first', 'difference']\n",
      "['first', 'prediction', 'information']\n",
      "['annotation', 'information']\n",
      "['second', 'difference']\n",
      "['first', 'prediction', 'information']\n",
      "['second', 'prediction', 'information']\n",
      "[]\n",
      "['network', 'parameter']\n",
      "['convolutional', 'neural', 'network']\n",
      "[]\n",
      "['first', 'difference']\n",
      "['second', 'difference']\n",
      "['method']\n",
      "['convolutional', 'neural', 'network']\n",
      "['method']\n",
      "['inter-frame', 'jitter']\n",
      "['video', 'frame', 'image']\n",
      "['detection', 'process']\n",
      "['video', 'processing', 'method']\n",
      "['convolution', 'neural', 'network', 'training', 'device']\n",
      "['video', 'processing', 'device']\n",
      "['electronic', 'device']\n",
      "['short-term', 'power', 'load', 'prediction', 'method']\n",
      "['power', 'system']\n",
      "['actual', 'power', 'consumption']\n",
      "['measured', 'power', 'load']\n",
      "['predicted', 'power', 'consumption']\n",
      "['measured', 'power', 'load']\n",
      "['network', 'prediction', 'model']\n",
      "['method']\n",
      "['deep', 'belief', 'network', 'prediction', 'model']\n",
      "['four-layer', 'network', 'structure']\n",
      "['actual', 'power', 'consumption']\n",
      "['measured', 'power', 'load']\n",
      "['deep', 'belief', 'network', 'prediction', 'model']\n",
      "['unsupervised', 'greedy', 'algorithm']\n",
      "['parameter', 'value']\n",
      "['layer']\n",
      "['deep', 'belief', 'network', 'prediction', 'model']\n",
      "['activation', 'function']\n",
      "['deep', 'belief', 'network', 'prediction', 'model']\n",
      "['mapping', 'relationship']\n",
      "['input']\n",
      "['output']\n",
      "['deep', 'belief', 'network', 'prediction', 'model']\n",
      "['training']\n",
      "['learning']\n",
      "['actual', 'power', 'consumption']\n",
      "['measured', 'power', 'load']\n",
      "['predicted', 'power', 'consumption']\n",
      "['measured', 'power', 'load']\n",
      "['depth', 'belief', 'network', 'prediction', 'model']\n",
      "['short-term', 'power', 'load', 'prediction', 'method']\n",
      "['power', 'system']\n",
      "['depth', 'belief', 'network', 'prediction', 'network']\n",
      "['power', 'load', 'power', 'prediction']\n",
      "['internal', 'relationship']\n",
      "['input']\n",
      "['output']\n",
      "['prediction']\n",
      "['load', 'power', 'consumption']\n",
      "['period']\n",
      "['time']\n",
      "['deep', 'structure']\n",
      "['network']\n",
      "['short-term', 'power', 'load', 'prediction', 'process']\n",
      "['accuracy']\n",
      "['speed']\n",
      "['prediction']\n",
      "['short-term', 'power', 'load', 'condition']\n",
      "['small', 'base', 'station']\n",
      "['control', 'method']\n",
      "['deep', 'neural', 'network']\n",
      "['real', 'value']\n",
      "['predicted', 'coordinate']\n",
      "['sample', 'error']\n",
      "['actual', 'coordinate']\n",
      "['predicted', 'coordinate']\n",
      "['method']\n",
      "['user', 'information']\n",
      "['base', 'station']\n",
      "['user', 'number']\n",
      "['access', 'time']\n",
      "['user', 'location', 'information']\n",
      "['base', 'station']\n",
      "['user', 'data']\n",
      "['base', 'station']\n",
      "['path', 'data']\n",
      "['model']\n",
      "['data', 'sample']\n",
      "['user']\n",
      "['sample', 'set']\n",
      "['training']\n",
      "['neural', 'network', 'model']\n",
      "['neural', 'network']\n",
      "['training', 'model']\n",
      "['average', 'square', 'error']\n",
      "['training', 'error']\n",
      "['commonly']\n",
      "['propagation', 'method']\n",
      "['training', 'result']\n",
      "['training']\n",
      "['reverse', 'propagation', 'method']\n",
      "['parameter']\n",
      "['neural', 'network']\n",
      "['real', 'value']\n",
      "['predicted', 'coordinate']\n",
      "['sample', 'error']\n",
      "['actual', 'coordinate']\n",
      "['predicted', 'coordinate']\n",
      "['data']\n",
      "['position']\n",
      "['user']\n",
      "['next', 'time']\n",
      "['small', 'base', 'station']\n",
      "['control', 'method']\n",
      "['deep', 'neural', 'network']\n",
      "['accuracy']\n",
      "['prediction']\n",
      "['practicality']\n",
      "['system']\n",
      "patent_content_tokenized [['method', 'convolutional neural network', 'network parameter', 'convolutional neural network', 'first difference', 'second difference', 'method', 'raw sample image', 'target object label information', 'scrambled sample image', 'original sample image', 'convolutional neural network', 'original image', 'original image', 'first prediction information', 'target object', 'sample image', 'second prediction information', 'target object', 'scrambled sample image', 'first difference', 'first prediction information', 'annotation information', 'second difference', 'first prediction information', 'second prediction information', 'network parameter', 'convolutional neural network', 'first difference', 'second difference', 'method', 'convolutional neural network', 'method', 'inter-frame jitter', 'video frame image', 'detection process', 'video processing method', 'convolution neural network training device', 'video processing device', 'electronic device'], ['short-term power load prediction method', 'power system', 'actual power consumption', 'measured power load', 'predicted power consumption', 'measured power load', 'network prediction model', 'method', 'deep belief network prediction model', 'four-layer network structure', 'actual power consumption', 'measured power load', 'deep belief network prediction model', 'unsupervised greedy algorithm', 'parameter value', 'layer', 'deep belief network prediction model', 'activation function', 'deep belief network prediction model', 'mapping relationship', 'input', 'output', 'deep belief network prediction model', 'training', 'learning', 'actual power consumption', 'measured power load', 'predicted power consumption', 'measured power load', 'depth belief network prediction model', 'short-term power load prediction method', 'power system', 'depth belief network prediction network', 'power load power prediction', 'internal relationship', 'input', 'output', 'prediction', 'load power consumption', 'period', 'time', 'deep structure', 'network', 'short-term power load prediction process', 'accuracy', 'speed', 'prediction', 'short-term power load condition'], ['small base station', 'control method', 'deep neural network', 'real value', 'predicted coordinate', 'sample error', 'actual coordinate', 'predicted coordinate', 'method', 'user information', 'base station', 'user number', 'access time', 'user location information', 'base station', 'user data', 'base station', 'path data', 'model', 'data sample', 'user', 'sample set', 'training', 'neural network model', 'neural network', 'training model', 'average square error', 'training error', 'commonly', 'propagation method', 'training result', 'training', 'reverse propagation method', 'parameter', 'neural network', 'real value', 'predicted coordinate', 'sample error', 'actual coordinate', 'predicted coordinate', 'data', 'position', 'user', 'next time', 'small base station', 'control method', 'deep neural network', 'accuracy', 'prediction', 'practicality', 'system']]\n"
     ]
    }
   ],
   "source": [
    "patent_content_tokenized=[]\n",
    "grammar = r\"\"\"\n",
    "                        NBAR:\n",
    "                            {<NN.*|JJ>*<NN.*>}  # Nouns and Adjectives, terminated with Nouns\n",
    "\n",
    "                        NP:\n",
    "                            {<NBAR>}\n",
    "                            {<NBAR><IN><NBAR>}  # Above, connected with in/of/etc...;IN代表介词\n",
    "                    \"\"\"\n",
    "\n",
    "for text in patent_content:\n",
    "    content_term =(ProcessDwpiText.get_term(text, grammar, \"NP\"))\n",
    "    term_list = itertools.chain((\" \".join(ab) for ab in content_term))\n",
    "    patent_content_tokenized.append(list(filter(None, term_list)))\n",
    "print(\"patent_content_tokenized\",patent_content_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['method',\n",
      "  'convolutional neural network',\n",
      "  'network parameter',\n",
      "  'convolutional neural network',\n",
      "  'first difference',\n",
      "  'second difference',\n",
      "  'method',\n",
      "  'scrambled sample image',\n",
      "  'convolutional neural network',\n",
      "  'original image',\n",
      "  'original image',\n",
      "  'first prediction information',\n",
      "  'target object',\n",
      "  'second prediction information',\n",
      "  'target object',\n",
      "  'scrambled sample image',\n",
      "  'first difference',\n",
      "  'first prediction information',\n",
      "  'second difference',\n",
      "  'first prediction information',\n",
      "  'second prediction information',\n",
      "  'network parameter',\n",
      "  'convolutional neural network',\n",
      "  'first difference',\n",
      "  'second difference',\n",
      "  'method',\n",
      "  'convolutional neural network',\n",
      "  'method'],\n",
      " ['short-term power load prediction method',\n",
      "  'power system',\n",
      "  'actual power consumption',\n",
      "  'measured power load',\n",
      "  'predicted power consumption',\n",
      "  'measured power load',\n",
      "  'method',\n",
      "  'deep belief network prediction model',\n",
      "  'actual power consumption',\n",
      "  'measured power load',\n",
      "  'deep belief network prediction model',\n",
      "  'deep belief network prediction model',\n",
      "  'deep belief network prediction model',\n",
      "  'input',\n",
      "  'output',\n",
      "  'deep belief network prediction model',\n",
      "  'training',\n",
      "  'actual power consumption',\n",
      "  'measured power load',\n",
      "  'predicted power consumption',\n",
      "  'measured power load',\n",
      "  'short-term power load prediction method',\n",
      "  'power system',\n",
      "  'input',\n",
      "  'output',\n",
      "  'prediction',\n",
      "  'accuracy',\n",
      "  'prediction'],\n",
      " ['small base station',\n",
      "  'control method',\n",
      "  'deep neural network',\n",
      "  'real value',\n",
      "  'predicted coordinate',\n",
      "  'sample error',\n",
      "  'actual coordinate',\n",
      "  'predicted coordinate',\n",
      "  'method',\n",
      "  'base station',\n",
      "  'base station',\n",
      "  'base station',\n",
      "  'user',\n",
      "  'training',\n",
      "  'neural network',\n",
      "  'training',\n",
      "  'neural network',\n",
      "  'real value',\n",
      "  'predicted coordinate',\n",
      "  'sample error',\n",
      "  'actual coordinate',\n",
      "  'predicted coordinate',\n",
      "  'user',\n",
      "  'small base station',\n",
      "  'control method',\n",
      "  'deep neural network',\n",
      "  'accuracy',\n",
      "  'prediction']]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for text in patent_content_tokenized:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "patent_content_tokenized = [[token for token in text if frequency[token] > 1] for text in patent_content_tokenized]\n",
    "pprint(patent_content_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(31 unique tokens: ['convolutional neural network', 'first difference', 'first prediction information', 'method', 'network parameter']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(patent_content_tokenized)\n",
    "dictionary.save('deeplearning.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 5),\n",
      "  (1, 3),\n",
      "  (2, 3),\n",
      "  (3, 4),\n",
      "  (4, 2),\n",
      "  (5, 2),\n",
      "  (6, 2),\n",
      "  (7, 3),\n",
      "  (8, 2),\n",
      "  (9, 2)],\n",
      " [(3, 1),\n",
      "  (10, 1),\n",
      "  (11, 3),\n",
      "  (12, 5),\n",
      "  (13, 2),\n",
      "  (14, 5),\n",
      "  (15, 2),\n",
      "  (16, 2),\n",
      "  (17, 2),\n",
      "  (18, 2),\n",
      "  (19, 2),\n",
      "  (20, 1)],\n",
      " [(3, 1),\n",
      "  (10, 1),\n",
      "  (18, 1),\n",
      "  (20, 2),\n",
      "  (21, 2),\n",
      "  (22, 3),\n",
      "  (23, 2),\n",
      "  (24, 2),\n",
      "  (25, 2),\n",
      "  (26, 4),\n",
      "  (27, 2),\n",
      "  (28, 2),\n",
      "  (29, 2),\n",
      "  (30, 2)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in patent_content_tokenized]\n",
    "corpora.MmCorpus.serialize('deeplearning.mm', corpus)\n",
    "pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.032*\"method\" + 0.032*\"deep belief network prediction model\" + 0.032*\"convolutional neural network\" + 0.032*\"prediction\" + 0.032*\"second difference\" + 0.032*\"actual power consumption\" + 0.032*\"measured power load\" + 0.032*\"predicted coordinate\" + 0.032*\"training\" + 0.032*\"neural network\"'),\n",
       " (1,\n",
       "  '0.152*\"convolutional neural network\" + 0.123*\"method\" + 0.094*\"first prediction information\" + 0.094*\"first difference\" + 0.094*\"second difference\" + 0.064*\"second prediction information\" + 0.064*\"network parameter\" + 0.064*\"original image\" + 0.064*\"scrambled sample image\" + 0.064*\"target object\"'),\n",
       " (2,\n",
       "  '0.090*\"predicted coordinate\" + 0.069*\"base station\" + 0.057*\"training\" + 0.053*\"deep belief network prediction model\" + 0.048*\"measured power load\" + 0.047*\"actual coordinate\" + 0.047*\"real value\" + 0.047*\"user\" + 0.047*\"small base station\" + 0.047*\"control method\"'),\n",
       " (3,\n",
       "  '0.144*\"measured power load\" + 0.135*\"deep belief network prediction model\" + 0.087*\"actual power consumption\" + 0.065*\"input\" + 0.065*\"short-term power load prediction method\" + 0.062*\"output\" + 0.061*\"prediction\" + 0.055*\"predicted power consumption\" + 0.050*\"power system\" + 0.036*\"accuracy\"'),\n",
       " (4,\n",
       "  '0.032*\"deep belief network prediction model\" + 0.032*\"predicted coordinate\" + 0.032*\"convolutional neural network\" + 0.032*\"method\" + 0.032*\"measured power load\" + 0.032*\"prediction\" + 0.032*\"first prediction information\" + 0.032*\"first difference\" + 0.032*\"output\" + 0.032*\"sample error\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from wordcloud import WordCloud\n",
    "NUM_TOPICS = 5\n",
    "model = models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word = dictionary, alpha = None)\n",
    "\n",
    "model.print_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of corpus—— 3\n",
      "[(0,\n",
      "  '0.151*\"convolutional neural network\" + 0.121*\"method\" + 0.093*\"second '\n",
      "  'difference\" + 0.093*\"first prediction information\" + 0.092*\"first '\n",
      "  'difference\" + 0.065*\"scrambled sample image\" + 0.064*\"network parameter\" + '\n",
      "  '0.064*\"original image\" + 0.064*\"second prediction information\" + '\n",
      "  '0.063*\"target object\"'),\n",
      " (1,\n",
      "  '0.123*\"predicted coordinate\" + 0.094*\"base station\" + 0.064*\"training\" + '\n",
      "  '0.064*\"small base station\" + 0.064*\"sample error\" + 0.064*\"actual '\n",
      "  'coordinate\" + 0.064*\"real value\" + 0.064*\"neural network\" + 0.064*\"control '\n",
      "  'method\" + 0.064*\"deep neural network\"'),\n",
      " (2,\n",
      "  '0.032*\"method\" + 0.032*\"deep belief network prediction model\" + '\n",
      "  '0.032*\"convolutional neural network\" + 0.032*\"measured power load\" + '\n",
      "  '0.032*\"prediction\" + 0.032*\"predicted coordinate\" + 0.032*\"first prediction '\n",
      "  'information\" + 0.032*\"first difference\" + 0.032*\"actual power consumption\" '\n",
      "  '+ 0.032*\"output\"'),\n",
      " (3,\n",
      "  '0.065*\"convolutional neural network\" + 0.063*\"method\" + 0.053*\"first '\n",
      "  'difference\" + 0.050*\"first prediction information\" + 0.048*\"second '\n",
      "  'difference\" + 0.045*\"target object\" + 0.043*\"second prediction information\" '\n",
      "  '+ 0.041*\"original image\" + 0.040*\"network parameter\" + 0.036*\"scrambled '\n",
      "  'sample image\"'),\n",
      " (4,\n",
      "  '0.152*\"deep belief network prediction model\" + 0.152*\"measured power load\" '\n",
      "  '+ 0.094*\"actual power consumption\" + 0.064*\"input\" + 0.064*\"power system\" + '\n",
      "  '0.064*\"prediction\" + 0.064*\"predicted power consumption\" + 0.064*\"output\" + '\n",
      "  '0.064*\"short-term power load prediction method\" + 0.035*\"method\"')]\n"
     ]
    }
   ],
   "source": [
    "print(\"length of corpus——\",len(corpus))\n",
    "\n",
    "#输出模型及模型中的各主题包含的词\n",
    "topictermlist = model.print_topics(-1)\n",
    "pprint(topictermlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032*\"method\" + 0.032*\"deep belief network prediction model\" + 0.032*\"convolutional neural network\" + 0.032*\"prediction\" + 0.032*\"second difference\" + 0.032*\"actual power consumption\" + 0.032*\"measured power load\" + 0.032*\"predicted coordinate\" + 0.032*\"training\" + 0.032*\"neural network\"\n",
      "0.152*\"convolutional neural network\" + 0.123*\"method\" + 0.094*\"first prediction information\" + 0.094*\"first difference\" + 0.094*\"second difference\" + 0.064*\"second prediction information\" + 0.064*\"network parameter\" + 0.064*\"original image\" + 0.064*\"scrambled sample image\" + 0.064*\"target object\"\n",
      "0.090*\"predicted coordinate\" + 0.069*\"base station\" + 0.057*\"training\" + 0.053*\"deep belief network prediction model\" + 0.048*\"measured power load\" + 0.047*\"actual coordinate\" + 0.047*\"real value\" + 0.047*\"user\" + 0.047*\"small base station\" + 0.047*\"control method\"\n",
      "0.144*\"measured power load\" + 0.135*\"deep belief network prediction model\" + 0.087*\"actual power consumption\" + 0.065*\"input\" + 0.065*\"short-term power load prediction method\" + 0.062*\"output\" + 0.061*\"prediction\" + 0.055*\"predicted power consumption\" + 0.050*\"power system\" + 0.036*\"accuracy\"\n",
      "0.032*\"deep belief network prediction model\" + 0.032*\"predicted coordinate\" + 0.032*\"convolutional neural network\" + 0.032*\"method\" + 0.032*\"measured power load\" + 0.032*\"prediction\" + 0.032*\"first prediction information\" + 0.032*\"first difference\" + 0.032*\"output\" + 0.032*\"sample error\"\n"
     ]
    }
   ],
   "source": [
    "for topic in model.print_topics(num_words=10):\n",
    "    print(topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.97239953)]\n",
      "[(3, 0.9722375)]\n",
      "[(2, 0.9723593)]\n",
      "0 [(1, 0.97239953)]\n",
      "1 [(3, 0.9722375)]\n",
      "2 [(2, 0.9723593)]\n"
     ]
    }
   ],
   "source": [
    "#text = [\"user\"]\n",
    "document_output=[]\n",
    "for text in patent_content_tokenized:\n",
    "    bow = dictionary.doc2bow(text)\n",
    "    #print(\"get_document_topics\", model.get_document_topics(bow))\n",
    "    d_topic=model.get_document_topics(bow)\n",
    "    print(d_topic)\n",
    "    #NUM_TOPICS代表最大主题个数，如何将其余主题为0的值补充进来？，如第1个文档里，补充[0,0],[2,0][3,0][4,0]\n",
    "    \n",
    "    document_output.append(d_topic)\n",
    "for index,pro in enumerate(document_output):\n",
    "    print(index,pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}